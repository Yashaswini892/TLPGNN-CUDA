{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKDZeAWJ5Seo",
        "outputId": "2ed62762-8fca-4043-dc37-5de3197d41ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install Ninja"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "KKSqBdct85Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CUDA SetUp"
      ],
      "metadata": {
        "id": "VP74rPMMmZdE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_jlwOqEnt2r",
        "outputId": "02d004cd-f8b3-4583-a086-a5a9feaea929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcEAp9aLoQiE",
        "outputId": "300ffedd-7d06-4d9f-f4a5-a2c8de796d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9vj9kwo8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9vj9kwo8\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfemnjtNCL52",
        "outputId": "d80d3da8-43af-4c51-931b-8078f0e41fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpfzqkpl_2\".\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/charlifu/TLPGNN.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7HBDOjp5YRZ",
        "outputId": "b7e9418f-9049-481f-c79d-cb475f7eb237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TLPGNN'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 52 (delta 9), reused 16 (delta 5), pack-reused 32\u001b[K\n",
            "Receiving objects: 100% (52/52), 59.75 MiB | 32.25 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd TLPGNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YCHzIfi5eGm",
        "outputId": "60bd2969-fdc6-468f-998e-cd598576e3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TLPGNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse, time\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda.profiler as profiler\n",
        "import scipy.sparse as sp\n",
        "from torch.utils.cpp_extension import load_inline"
      ],
      "metadata": {
        "id": "AyX8Uzzl9E7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse, time\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda.profiler as profiler\n",
        "import scipy.sparse as sp\n",
        "from torch.utils.cpp_extension import load_inline\n",
        "\n",
        "def read_data(dataset):\n",
        "    data_path = \"/content/TLPGNN/data/citeseer/\"\n",
        "    ret = {}\n",
        "    ret['features'] = np.load(data_path+'features.npy')\n",
        "    ret['graph'] = sp.load_npz(data_path+'csr.npz').tocsc()\n",
        "    ret['graph'].sort_indices()\n",
        "    return ret\n",
        "\n",
        "cpp_source = '''\n",
        "#include <vector>\n",
        "\n",
        "\n",
        "std::vector<torch::Tensor> gcn_conv_cuda_forward(\n",
        "        torch::Tensor features,\n",
        "        torch::Tensor col_starts,\n",
        "        torch::Tensor rows);\n",
        "\n",
        "std::vector<torch::Tensor> gcn_conv_cuda_backward(\n",
        "        torch::Tensor features,\n",
        "        torch::Tensor grad,\n",
        "        torch::Tensor indegs,\n",
        "        torch::Tensor row_starts,\n",
        "        torch::Tensor cols);\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "std::vector<torch::Tensor> gcn_conv_forward(\n",
        "        torch::Tensor features,\n",
        "        torch::Tensor col_starts,\n",
        "        torch::Tensor rows)\n",
        "{\n",
        "    CHECK_INPUT(features);\n",
        "    CHECK_INPUT(col_starts);\n",
        "    CHECK_INPUT(rows);\n",
        "\n",
        "    return gcn_conv_cuda_forward(features, col_starts, rows);\n",
        "}\n",
        "\n",
        "std::vector<torch::Tensor> gcn_conv_backward(\n",
        "        torch::Tensor features,\n",
        "        torch::Tensor grad,\n",
        "        torch::Tensor indegs,\n",
        "        torch::Tensor row_starts,\n",
        "        torch::Tensor cols)\n",
        "{\n",
        "    CHECK_INPUT(features);\n",
        "    CHECK_INPUT(grad);\n",
        "    CHECK_INPUT(indegs);\n",
        "    CHECK_INPUT(row_starts);\n",
        "    CHECK_INPUT(cols);\n",
        "\n",
        "    return gcn_conv_cuda_backward(features, grad, indegs, row_starts, cols);\n",
        "}\n",
        "\n",
        "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
        "    m.def(\"forward\", &gcn_conv_forward, \"GCN conv forward (CUDA)\");\n",
        "    m.def(\"backward\", &gcn_conv_backward, \"GCN conv backward (CUDA)\");\n",
        "}\n",
        "'''\n",
        "\n",
        "cuda_source = open(\"/content/TLPGNN/gcn/naive_kernel.cu\").read()\n",
        "\n",
        "gcn_module = load_inline(name=\"cn\",\n",
        "        cpp_sources=[cpp_source],\n",
        "        cuda_sources=[cuda_source],\n",
        "        extra_cuda_cflags=['-Xptxas -O3 -m 64'],\n",
        "        verbose=False)\n",
        "\n",
        "\n",
        "def main(dataset=\"citeseer\", size=32, gpu=0):\n",
        "    th.cuda.set_device(gpu)\n",
        "    data = read_data(dataset)\n",
        "    features = th.cuda.FloatTensor(data['features'][:,0:size])\n",
        "    indptr = data['graph'].indptr\n",
        "    #indegs = th.cuda.FloatTensor([indptr[i+1] - indptr[i] for i in range(len(indptr)-1)])\n",
        "    col_starts = th.cuda.IntTensor(indptr)\n",
        "    rows = th.cuda.IntTensor(data['graph'].indices)\n",
        "    #row_starts = th.cuda.IntTensor(data['graph'].tocsr().indptr)\n",
        "    #cols = th.cuda.IntTensor(data['graph'].tocsr().indices)\n",
        "\n",
        "    gcn_module.forward(features, col_starts, rows)\n",
        "    th.cuda.synchronize()\n",
        "\n",
        "    run_time = 0.0\n",
        "    for _ in range(10):\n",
        "        start_run = time.perf_counter()\n",
        "        rst = gcn_module.forward(features, col_starts, rows)\n",
        "        th.cuda.synchronize()\n",
        "        run_time += (time.perf_counter() - start_run)\n",
        "\n",
        "    print('Time (ms): {:.3f}'.format(run_time*1e3/10))\n",
        "\n",
        "    return run_time * 1e3 / 10\n",
        "    # t = time.time()\n",
        "    # rst = gcn_module.backward(features, th.ones_like(features), indegs, row_starts, cols)\n",
        "    # th.cuda.synchronize()\n",
        "    # print(time.time() - t)\n",
        "    # print(rst[0])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oEnL3Jl5pT3",
        "outputId": "68515277-95f7-4db3-f539-4c7ea176ece5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "[tensor([[-0.2550,  1.2813, -0.2190,  ...,  0.6278, -0.5823,  1.4813],\n",
            "        [-0.4947,  0.5090,  0.7407,  ...,  0.7368, -0.2246, -1.1289],\n",
            "        [-0.7635, -0.5570,  0.0670,  ...,  0.9008,  0.0640,  2.0496],\n",
            "        ...,\n",
            "        [-0.0403,  0.3058,  1.1747,  ...,  0.7907,  0.1276, -0.8182],\n",
            "        [ 0.6092,  0.6710, -1.5096,  ...,  0.6340, -0.5538, -1.3590],\n",
            "        [-0.5272, -0.7489, -0.3915,  ..., -0.6998, -0.3895, -1.1157]],\n",
            "       device='cuda:0')]\n",
            "Time (ms): 54.696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch data.json"
      ],
      "metadata": {
        "id": "byzTveyhZoKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <json-c/json.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define DATA_FILE \"data.json\"\n",
        "\n",
        "typedef struct {\n",
        "    float *features;\n",
        "    int *col_starts;\n",
        "    int *rows;\n",
        "    int n_vertex;\n",
        "    int fsize;\n",
        "} Dataset;\n",
        "\n",
        "Dataset load_dataset(const char *filename) {\n",
        "    Dataset dataset;\n",
        "    dataset.features = NULL;\n",
        "    dataset.col_starts = NULL;\n",
        "    dataset.rows = NULL;\n",
        "    dataset.n_vertex = 0;\n",
        "    dataset.fsize = 0;\n",
        "\n",
        "    // Read JSON file\n",
        "    FILE *file = fopen(filename, \"r\");\n",
        "    if (!file) {\n",
        "        fprintf(stderr, \"Failed to open file %s\\n\", filename);\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    fseek(file, 0, SEEK_END);\n",
        "    long file_size = ftell(file);\n",
        "    fseek(file, 0, SEEK_SET);\n",
        "\n",
        "    char *json_str = (char *)malloc(file_size + 1);\n",
        "    if (!json_str) {\n",
        "        fclose(file);\n",
        "        fprintf(stderr, \"Memory allocation failed\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    fread(json_str, 1, file_size, file);\n",
        "    fclose(file);\n",
        "    json_str[file_size] = '\\0';\n",
        "\n",
        "    // Parse JSON\n",
        "    struct json_object *root = json_tokener_parse(json_str);\n",
        "    free(json_str);\n",
        "\n",
        "    // Extract data\n",
        "    struct json_object *features_obj, *graph_obj;\n",
        "    json_object_object_get_ex(root, \"features\", &features_obj);\n",
        "    json_object_object_get_ex(root, \"graph\", &graph_obj);\n",
        "\n",
        "    // Extract features\n",
        "    int features_len = json_object_array_length(features_obj);\n",
        "    dataset.features = (float *)malloc(features_len * sizeof(float));\n",
        "    if (!dataset.features) {\n",
        "        json_object_put(root);\n",
        "        fprintf(stderr, \"Memory allocation failed\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < features_len; ++i) {\n",
        "        struct json_object *item = json_object_array_get_idx(features_obj, i);\n",
        "        dataset.features[i] = json_object_get_double(item);\n",
        "    }\n",
        "\n",
        "    // Extract graph\n",
        "    struct json_object *col_starts_obj, *rows_obj;\n",
        "    json_object_object_get_ex(graph_obj, \"col_starts\", &col_starts_obj);\n",
        "    json_object_object_get_ex(graph_obj, \"rows\", &rows_obj);\n",
        "\n",
        "    int col_starts_len = json_object_array_length(col_starts_obj);\n",
        "    int rows_len = json_object_array_length(rows_obj);\n",
        "\n",
        "    dataset.col_starts = (int *)malloc(col_starts_len * sizeof(int));\n",
        "    dataset.rows = (int *)malloc(rows_len * sizeof(int));\n",
        "\n",
        "    if (!dataset.col_starts || !dataset.rows) {\n",
        "        free(dataset.features);\n",
        "        json_object_put(root);\n",
        "        fprintf(stderr, \"Memory allocation failed\\n\");\n",
        "        exit(EXIT_FAILURE);\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < col_starts_len; ++i) {\n",
        "        struct json_object *item = json_object_array_get_idx(col_starts_obj, i);\n",
        "        dataset.col_starts[i] = json_object_get_int(item);\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < rows_len; ++i) {\n",
        "        struct json_object *item = json_object_array_get_idx(rows_obj, i);\n",
        "        dataset.rows[i] = json_object_get_int(item);\n",
        "    }\n",
        "\n",
        "    dataset.n_vertex = rows_len; // Assuming rows length is the number of vertices\n",
        "    dataset.fsize = features_len / rows_len; // Assuming features length is a multiple of rows length\n",
        "\n",
        "    // Clean up\n",
        "    json_object_put(root);\n",
        "\n",
        "    return dataset;\n",
        "}\n",
        "\n",
        "__global__ void gcn_conv_cuda_forward_kernel(\n",
        "        const int n_vertex,\n",
        "        const int fsize,\n",
        "        float *features,\n",
        "        int *col_starts,\n",
        "        int *rows,\n",
        "        float *result) {\n",
        "\n",
        "    int des_v = blockIdx.x * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (des_v < n_vertex)\n",
        "    {\n",
        "        float ret;\n",
        "\n",
        "        int s_pos = col_starts[des_v];\n",
        "        int e_pos = col_starts[des_v+1];\n",
        "\n",
        "        float deg = 1.0 / (e_pos - s_pos);\n",
        "        float *des_p = result + des_v * fsize;\n",
        "        for (int k = threadIdx.x; k < fsize; k += blockDim.x) {\n",
        "            ret = 0.0;\n",
        "            for (int i = s_pos; i < e_pos; ++i)\n",
        "            {\n",
        "                ret += __ldg(features + rows[i] * fsize + k);\n",
        "            }\n",
        "            des_p[k] = ret * deg;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Load dataset\n",
        "    Dataset dataset = load_dataset(DATA_FILE);\n",
        "\n",
        "    // Print dataset info\n",
        "    printf(\"Number of vertices: %d\\n\", dataset.n_vertex);\n",
        "    printf(\"Feature size: %d\\n\", dataset.fsize);\n",
        "\n",
        "    // Allocate device memory\n",
        "    float *d_features, *d_result;\n",
        "    int *d_col_starts, *d_rows;\n",
        "    cudaMalloc((void **)&d_features, dataset.n_vertex * dataset.fsize * sizeof(float));\n",
        "    cudaMalloc((void **)&d_result, dataset.n_vertex * dataset.fsize * sizeof(float));\n",
        "    cudaMalloc((void **)&d_col_starts, (dataset.n_vertex + 1) * sizeof(int));\n",
        "    cudaMalloc((void **)&d_rows, dataset.n_vertex * sizeof(int));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_features, dataset.features, dataset.n_vertex * dataset.fsize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_col_starts, dataset.col_starts, (dataset.n_vertex + 1) * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_rows, dataset.rows, dataset.n_vertex * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    int num_blocks = (dataset.n_vertex + 3) / 4; // Adjust based on block size\n",
        "    dim3 threads_per_block(32, 4);\n",
        "    gcn_conv_cuda_forward_kernel<<<num_blocks, threads_per_block>>>(dataset.n_vertex, dataset.fsize, d_features, d_col_starts, d_rows, d_result);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_features);\n",
        "    cudaFree(d_result);\n",
        "    cudaFree(d_col_starts);\n",
        "    cudaFree(d_rows);\n",
        "\n",
        "    // Free host memory\n",
        "    free(dataset.features);\n",
        "    free(dataset.col_starts);\n",
        "    free(dataset.rows);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aKNsWAl6PPY",
        "outputId": "a1b5d941-b81d-4661-c76f-befd7248abbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/ld: /tmp/tmpxft_000024f8_00000000-11_single_file.o: in function `load_dataset(char const*)':\n",
            "tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x1ad): undefined reference to `json_tokener_parse'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x1d7): undefined reference to `json_object_object_get_ex'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x1f1): undefined reference to `json_object_object_get_ex'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x1fd): undefined reference to `json_object_array_length'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x239): undefined reference to `json_object_put'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x28a): undefined reference to `json_object_array_get_idx'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x29a): undefined reference to `json_object_get_double'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x2e7): undefined reference to `json_object_object_get_ex'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x301): undefined reference to `json_object_object_get_ex'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x30d): undefined reference to `json_object_array_length'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x31c): undefined reference to `json_object_array_length'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x39b): undefined reference to `json_object_put'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x3ec): undefined reference to `json_object_array_get_idx'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x417): undefined reference to `json_object_get_int'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x449): undefined reference to `json_object_array_get_idx'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x471): undefined reference to `json_object_get_int'\n",
            "/usr/bin/ld: tmpxft_000024f8_00000000-6_single_file.cudafe1.cpp:(.text+0x4ab): undefined reference to `json_object_put'\n",
            "collect2: error: ld returned 1 exit status\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e80assr5dJpm",
        "outputId": "6d6cd374-e729-47bd-db34-82a875ec3454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dgl"
      ],
      "metadata": {
        "id": "fFOTavo8eYcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "effb2409-b7d5-40e4-a984-e55b78feed77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/dmlc/dgl.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANWbY2cQfvQr",
        "outputId": "431e467b-7c3b-43e1-d628-5c8515a3e939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dgl'...\n",
            "remote: Enumerating objects: 53072, done.\u001b[K\n",
            "remote: Counting objects: 100% (4403/4403), done.\u001b[K\n",
            "remote: Compressing objects: 100% (412/412), done.\u001b[K\n",
            "remote: Total 53072 (delta 4150), reused 4071 (delta 3985), pack-reused 48669\u001b[K\n",
            "Receiving objects: 100% (53072/53072), 27.91 MiB | 8.44 MiB/s, done.\n",
            "Resolving deltas: 100% (35872/35872), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m-c8I7Bk0F8",
        "outputId": "8e18e03b-1277-4669-d39b-edfe9ab6911a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dgl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 \"/content/dgl/examples/pytorch/gcn/train.py\" --dataset cora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dgv24swjDcG",
        "outputId": "48432230-6b58-4ebb-cdf6-d50e4a1b198a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Training with DGL built-in GraphConv module.\n",
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "/root/.dgl/cora_v2.zip: 100% 132k/132k [00:00<00:00, 424kB/s] \n",
            "Extracting file to /root/.dgl/cora_v2_d697a464\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/dgl/examples/pytorch/gcn/train.py\", line 98, in <module>\n",
            "    g = g.int().to(device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dgl/heterograph.py\", line 5714, in to\n",
            "    ret._graph = self._graph.copy_to(utils.to_dgl_context(device))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dgl/heterograph_index.py\", line 255, in copy_to\n",
            "    return _CAPI_DGLHeteroCopyTo(self, ctx.device_type, ctx.device_id)\n",
            "  File \"dgl/_ffi/_cython/./function.pxi\", line 295, in dgl._ffi._cy3.core.FunctionBase.__call__\n",
            "  File \"dgl/_ffi/_cython/./function.pxi\", line 227, in dgl._ffi._cy3.core.FuncCall\n",
            "  File \"dgl/_ffi/_cython/./function.pxi\", line 217, in dgl._ffi._cy3.core.FuncCall3\n",
            "dgl._ffi.base.DGLError: [18:07:07] /opt/dgl/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.\n",
            "Stack trace:\n",
            "  [bt] (0) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x67) [0x796d139621b7]\n",
            "  [bt] (1) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, bool)+0x2a5) [0x796d13dbae85]\n",
            "  [bt] (2) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DGLContext, bool)+0x1ea) [0x796d13db789a]\n",
            "  [bt] (3) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x130) [0x796d13dd0e60]\n",
            "  [bt] (4) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DGLContext const&) const+0xb5) [0x796d13e05c45]\n",
            "  [bt] (5) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0x1e7) [0x796d13ef7e27]\n",
            "  [bt] (6) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0xfa) [0x796d13e11a0a]\n",
            "  [bt] (7) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(+0x6226d6) [0x796d13e226d6]\n",
            "  [bt] (8) /usr/local/lib/python3.10/dist-packages/dgl/libdgl.so(DGLFuncCall+0x4c) [0x796d13db9e2c]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    def forward(self, g, features):\n",
        "        h = features\n",
        "        run_times = []\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            if i != 0:\n",
        "                h = self.dropout(h)\n",
        "            with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "                h = layer(g, h)\n",
        "            run_time = 0.0\n",
        "            for event in prof.function_events:\n",
        "                if event.name == 'GCNConv':\n",
        "                    run_time = event.self_cpu_time_total / 1000.0  # Convert to milliseconds\n",
        "            run_times.append(run_time)\n",
        "        return h, run_times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQNcDh2-j4fy",
        "outputId": "be5d3258-c656-4c41-c570-0f1671fddd7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dgl  my.cu  sample_data  TLPGNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
        "    h = layer(g, h)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n",
        "Epoch 00170 | Loss 0.3201 | Accuracy 0.7780\n",
        "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------\n",
        "                         Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls\n",
        "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------\n",
        "                    aten::mul        49.99%       4.399ms        49.99%       4.399ms       2.200ms       4.432ms        50.17%       4.432ms       2.216ms             2\n",
        "                     aten::mm        30.91%       2.720ms        30.98%       2.726ms       2.726ms       2.733ms        30.94%       2.744ms       2.744ms             1\n",
        "              cudaEventRecord         3.88%     341.000us         3.88%     341.000us       1.894us       0.000us         0.00%       0.000us       0.000us           180\n",
        "                        GSpMM         3.11%     274.000us         4.36%     384.000us     384.000us     279.000us         3.16%     392.000us     392.000us             1\n",
        "                    aten::pow         1.88%     165.000us         2.20%     194.000us      97.000us     100.000us         1.13%     204.000us     102.000us             2\n",
        "                 aten::arange         1.58%     139.000us         2.88%     253.000us      42.167us     147.000us         1.66%     280.000us      46.667us             6\n",
        "               aten::_to_copy         1.36%     120.000us         2.19%     193.000us      38.600us     119.000us         1.35%     214.000us      42.800us             5\n",
        "                    aten::add         0.60%      53.000us         0.60%      53.000us      53.000us      61.000us         0.69%      61.000us      61.000us             1\n",
        "             aten::as_strided         0.52%      46.000us         0.52%      46.000us       5.750us      85.000us         0.96%      85.000us      10.625us             8\n",
        "                     aten::to         0.51%      45.000us         2.85%     251.000us      27.889us      75.000us         0.85%     289.000us      32.111us             9\n",
        "                    aten::min         0.50%      44.000us         1.08%      95.000us      95.000us      43.000us         0.49%      98.000us      98.000us             1\n",
        "                  aten::clamp         0.41%      36.000us         0.56%      49.000us      24.500us      58.000us         0.66%      67.000us      33.500us             2\n",
        "                    aten::any         0.40%      35.000us         0.51%      45.000us      45.000us      38.000us         0.43%      50.000us      50.000us             1\n",
        "                     aten::eq         0.36%      32.000us         1.00%      88.000us      88.000us      37.000us         0.42%      94.000us      94.000us             1\n",
        "                  aten::copy_         0.35%      31.000us         0.35%      31.000us       6.200us      55.000us         0.62%      55.000us      11.000us             5\n",
        "                  aten::fill_         0.34%      30.000us         0.34%      30.000us      10.000us      43.000us         0.49%      43.000us      14.333us             3\n",
        "                    aten::sum         0.33%      29.000us         0.80%      70.000us      70.000us      29.000us         0.33%      74.000us      74.000us             1\n",
        "              aten::clamp_min         0.32%      28.000us         0.32%      28.000us      28.000us      54.000us         0.61%      54.000us      54.000us             1\n",
        "                   aten::relu         0.31%      27.000us         0.91%      80.000us      80.000us      34.000us         0.38%      88.000us      88.000us             1\n",
        "                   aten::item         0.27%      24.000us         0.41%      36.000us      12.000us      31.000us         0.35%      47.000us      15.667us             3\n",
        "                 aten::matmul         0.26%      23.000us        31.32%       2.756ms       2.756ms      17.000us         0.19%       2.761ms       2.761ms             1\n",
        "                aten::reshape         0.24%      21.000us         0.44%      39.000us      19.500us      27.000us         0.31%      49.000us      24.500us             2\n",
        "                  aten::zeros         0.23%      20.000us         0.80%      70.000us      70.000us      19.000us         0.22%      74.000us      74.000us             1\n",
        "             aten::unsqueeze_         0.17%      15.000us         0.26%      23.000us      11.500us      17.000us         0.19%      29.000us      14.500us             2\n",
        "               aten::squeeze_         0.17%      15.000us         0.23%      20.000us      10.000us      17.000us         0.19%      26.000us      13.000us             2\n",
        "                  aten::empty         0.16%      14.000us         0.16%      14.000us       3.500us      34.000us         0.38%      34.000us       8.500us             4\n",
        "        cudaDeviceSynchronize         0.16%      14.000us         0.16%      14.000us      14.000us       0.000us         0.00%       0.000us       0.000us             1\n",
        "                   aten::view         0.14%      12.000us         0.14%      12.000us       6.000us      22.000us         0.25%      22.000us      11.000us             2\n",
        "          aten::empty_strided         0.13%      11.000us         0.13%      11.000us       2.200us      40.000us         0.45%      40.000us       8.000us             5\n",
        "             aten::is_nonzero         0.11%      10.000us         0.34%      30.000us      30.000us      15.000us         0.17%      36.000us      36.000us             1\n",
        "                  aten::zero_         0.11%      10.000us         0.47%      41.000us      41.000us      11.000us         0.12%      45.000us      45.000us             1\n",
        "                aten::resize_         0.08%       7.000us         0.08%       7.000us       2.333us      22.000us         0.25%      22.000us       7.333us             3\n",
        "    aten::_local_scalar_dense         0.05%       4.000us         0.05%       4.000us       1.333us      16.000us         0.18%      16.000us       5.333us             3\n",
        "            aten::as_strided_         0.05%       4.000us         0.05%       4.000us       1.000us      21.000us         0.24%      21.000us       5.250us             4\n",
        "            aten::result_type         0.01%       1.000us         0.01%       1.000us       0.500us      92.000us         1.04%      92.000us      46.000us             2\n",
        "           aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us      11.000us         0.12%      11.000us       3.667us             3\n",
        "-----------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------\n",
        "Self CPU time total: 8.799ms\n",
        "Self CUDA time total: 8.834ms"
      ],
      "metadata": {
        "id": "25WuQ0FvkLEx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}